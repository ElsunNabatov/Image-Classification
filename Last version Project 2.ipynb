{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd8ARrI3gmAT"
      },
      "source": [
        "# **Fine-Grained Classification**\n",
        "### Elsun Nabatov"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This project embarked on a journey to develop a neural network model capable of identifying specific airplane models from a diverse and detailed dataset. Leveraging the power of transfer learning, state-of-the-art architectures, and innovative data preprocessing techniques, it aimed to bridge the gap between generic object detection and the precise classification of nearly indistinguishable categories. The task was not merely an exercise in technical skill but a venture into the art of fine-tuning and optimization, exploring the limits of current methodologies and seeking new pathways to accuracy and efficiency in image classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Data Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first step in the project involved setting up the environment and accessing the dataset stored on Google Drive. The dataset includes images of airplanes and is split into three parts: training, validation, and test sets. This structure is ideal for training machine learning models, where the model is trained on the training set, hyper-parameters are optimized using the validation set, and the final model's performance is evaluated on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WqKQs3ugozA",
        "outputId": "0af2f841-3a68-4575-9a43-d91f9103039a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "R-rgMNDQgzrG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Directory paths\n",
        "dataset_dir = '/content/drive/My Drive/dataset'\n",
        "data_dir = '/content/drive/My Drive/data'\n",
        "images_dir = os.path.join(data_dir, 'images')  # The directory where images are stored"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "9fcolNm2g3-x"
      },
      "outputs": [],
      "source": [
        "# Load .csv files\n",
        "train_csv = pd.read_csv(os.path.join(dataset_dir, 'train.csv'))\n",
        "val_csv = pd.read_csv(os.path.join(dataset_dir, 'val.csv'))\n",
        "test_csv = pd.read_csv(os.path.join(dataset_dir, 'test.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "PXMTTcX6jTE_"
      },
      "outputs": [],
      "source": [
        "# Load class information\n",
        "families = pd.read_csv(os.path.join(data_dir, 'families.txt'), header=None)\n",
        "variants = pd.read_csv(os.path.join(data_dir, 'variants.txt'), header=None)\n",
        "manufacturers = pd.read_csv(os.path.join(data_dir, 'manufacturers.txt'), header=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Data Preprocessing and Augmentation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To enhance the model's ability to generalize from the training data and improve its performance on unseen data, image data augmentation techniques were applied. This process included random transformations such as rotation, width and height shifts, shear, zoom, and horizontal flipping. These transformations introduce variability in the training data without changing the labels, helping the model learn more robust features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "sZPs9iEUjVyw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input, EfficientNetB7\n",
        "\n",
        "# Preprocessing and data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WLfBGAsjY5H",
        "outputId": "0f39fa12-d608-442d-8bcf-ed38033c0235"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3334 validated image filenames belonging to 100 classes.\n",
            "Found 3333 validated image filenames belonging to 100 classes.\n",
            "Found 3333 validated image filenames belonging to 100 classes.\n"
          ]
        }
      ],
      "source": [
        "# Creating data generators\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_csv,\n",
        "    directory=images_dir,\n",
        "    x_col='filename',\n",
        "    y_col='Classes',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_csv,\n",
        "    directory=images_dir,\n",
        "    x_col='filename',\n",
        "    y_col='Classes',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_csv,\n",
        "    directory=images_dir,\n",
        "    x_col='filename',\n",
        "    y_col='Classes',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False   # Important for test set to not shuffle data\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Data Integrity Check**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To ensure the integrity of the dataset and avoid issues during training, a check was performed to confirm that all filenames listed in the CSV files correspond to actual image files in the dataset directories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QrR_3UWkBJP",
        "outputId": "db90a3b3-0d54-4eaf-de17-087dc4a3520e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Non-matching training filenames: []\n",
            "Non-matching validation filenames: []\n",
            "Non-matching test filenames: []\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "dataset_dir = '/content/drive/My Drive/dataset'  # dataset directory path\n",
        "data_dir = '/content/drive/My Drive/data'  # data directory path\n",
        "images_dir = os.path.join(data_dir, 'images')  # The directory where images are stored\n",
        "\n",
        "# Load the CSV files\n",
        "train_csv = pd.read_csv(os.path.join(dataset_dir, 'train.csv'))\n",
        "val_csv = pd.read_csv(os.path.join(dataset_dir, 'val.csv'))\n",
        "test_csv = pd.read_csv(os.path.join(dataset_dir, 'test.csv'))\n",
        "\n",
        "# Function to check for non-matching files\n",
        "def find_non_matching_filenames(df, images_dir):\n",
        "    non_matching_files = []\n",
        "    for index, row in df.iterrows():\n",
        "        image_path = os.path.join(images_dir, row['filename'])\n",
        "        if not os.path.isfile(image_path):\n",
        "            non_matching_files.append(row['filename'])\n",
        "    return non_matching_files\n",
        "\n",
        "# Find non-matching filenames in each set\n",
        "non_matching_train = find_non_matching_filenames(train_csv, images_dir)\n",
        "non_matching_val = find_non_matching_filenames(val_csv, images_dir)\n",
        "non_matching_test = find_non_matching_filenames(test_csv, images_dir)\n",
        "\n",
        "# Print out the non-matching filenames\n",
        "print(f\"Non-matching training filenames: {non_matching_train}\")\n",
        "print(f\"Non-matching validation filenames: {non_matching_val}\")\n",
        "print(f\"Non-matching test filenames: {non_matching_test}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-szGtlrUa3K"
      },
      "source": [
        "### **Model Development and Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the data prepared and preprocessed, the next step was to develop the model for classification. For this project, I chose to use the EfficientNetB7 architecture due to its excellent balance between accuracy and computational efficiency. EfficientNetB7 is a state-of-the-art model pre-trained on the ImageNet dataset, making it an excellent choice for transfer learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "RmJdSnLGUTeA"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input, # EfficientNet's own preprocess input function\n",
        "    rotation_range=30,   # Degree range for random rotations\n",
        "    width_shift_range=0.2,  # Range (as a fraction of total width) for random horizontal shifts\n",
        "    height_shift_range=0.2,  # Range (as a fraction of total height) for random vertical shifts\n",
        "    shear_range=0.2,  # Shear intensity (shear angle in degrees)\n",
        "    zoom_range=0.2,  # Range for random zoom\n",
        "    horizontal_flip=True,  # Randomly flip inputs horizontally\n",
        "    fill_mode='nearest'  # Strategy to fill newly created pixels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mta4KSCcUlLP"
      },
      "source": [
        "By utilizing transfer learning, the model benefits from the pre-trained weights of EfficientNetB7, significantly reducing the time and resources required for training from scratch. I added custom layers on top, including a Dense layer with 1024 units and a dropout layer to prevent overfitting. The final output layer has a softmax activation function, suitable for multi-class classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "j9zqpbpvqXLK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "\n",
        "# Load the pre-trained model with weights and exclude the top layer.\n",
        "model = EfficientNetB7(include_top=False, weights='imagenet', input_shape=(224, 224, 3), pooling='max')\n",
        "\n",
        "# Adding custom layers on top of EfficientNet\n",
        "model = keras.Sequential([\n",
        "    model,\n",
        "    keras.layers.Dense(1024, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(len(train_generator.class_indices), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss=CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Training Process**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model was trained for 10 epochs with early stopping and model checkpoint callbacks to save the best model based on validation loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "gXTQEg9msifO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = load_model('/content/drive/My Drive/best_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The training process showed promising results, with the model achieving an accuracy of up to 88.09% on the training set and 69.82% on the validation set. These results indicate that the model was learning effectively from the training data and making reasonable predictions on unseen validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKDiFF0rq8tJ",
        "outputId": "f1139a31-60ed-4f54-9286-be084908dbaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "105/105 [==============================] - 114s 1s/step - loss: 0.5784 - accuracy: 0.8233 - val_loss: 1.2643 - val_accuracy: 0.6697\n",
            "Epoch 2/10\n",
            "105/105 [==============================] - 109s 1s/step - loss: 0.5802 - accuracy: 0.8203 - val_loss: 1.2660 - val_accuracy: 0.6928\n",
            "Epoch 3/10\n",
            "105/105 [==============================] - 108s 1s/step - loss: 0.5078 - accuracy: 0.8338 - val_loss: 1.2841 - val_accuracy: 0.6640\n",
            "Epoch 4/10\n",
            "105/105 [==============================] - 108s 1s/step - loss: 0.5157 - accuracy: 0.8329 - val_loss: 1.5771 - val_accuracy: 0.6331\n",
            "Epoch 5/10\n",
            "105/105 [==============================] - 118s 1s/step - loss: 0.4363 - accuracy: 0.8599 - val_loss: 1.2297 - val_accuracy: 0.6982\n",
            "Epoch 6/10\n",
            "105/105 [==============================] - 110s 1s/step - loss: 0.4320 - accuracy: 0.8584 - val_loss: 1.4827 - val_accuracy: 0.6637\n",
            "Epoch 7/10\n",
            "105/105 [==============================] - 108s 1s/step - loss: 0.4243 - accuracy: 0.8626 - val_loss: 1.4469 - val_accuracy: 0.6775\n",
            "Epoch 8/10\n",
            "105/105 [==============================] - 107s 1s/step - loss: 0.4605 - accuracy: 0.8623 - val_loss: 1.3684 - val_accuracy: 0.6754\n",
            "Epoch 9/10\n",
            "105/105 [==============================] - 108s 1s/step - loss: 0.3844 - accuracy: 0.8809 - val_loss: 1.6591 - val_accuracy: 0.6622\n",
            "Epoch 10/10\n",
            "105/105 [==============================] - 108s 1s/step - loss: 0.5291 - accuracy: 0.8398 - val_loss: 1.5105 - val_accuracy: 0.6370\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint('/content/drive/My Drive/best_model.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=10,\n",
        "    callbacks=[checkpoint, early_stop]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQA3RWpwyhVJ",
        "outputId": "27a70b42-a2a6-4cef-e162-edd5eb782e0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "105/105 [==============================] - 35s 331ms/step - loss: 1.5105 - accuracy: 0.6370\n",
            "Validation Loss: 1.5105085372924805, Validation Accuracy: 0.6369637250900269\n",
            "105/105 [==============================] - 1756s 17s/step - loss: 1.4731 - accuracy: 0.6484\n",
            "Test Loss: 1.473116397857666, Test Accuracy: 0.6483648419380188\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on validation set\n",
        "val_loss, val_accuracy = model.evaluate(val_generator)\n",
        "print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_generator.reset()\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNARxtRoh8-e"
      },
      "source": [
        "### **Hyperparameter Tuning and Model Optimization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After evaluating my model on both the validation and test sets, I observed a validation accuracy of 63.70% and a test accuracy of 64.84%. Although these results were promising, they indicated a need for further improvement to meet the project's accuracy benchmarks. Here’s a detailed account of my approach to hyperparameter tuning and model optimization, aiming for higher performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data Augmentation: I significantly enhanced data augmentation techniques, such as increasing rotation and shift ranges, introducing shear and zoom variations, and adjusting brightness, aiming to boost the model's robustness and adaptability to diverse image conditions.\n",
        "\n",
        "Learning Rate Scheduler: I implemented a learning rate scheduler, starting with an initial rate of 0.0001 and applying a decay factor of 0.5 every 10 epochs, to enable more precise model weight adjustments and improve convergence.\n",
        "\n",
        "Batch Size Adjustment: Reducing the batch size from 32 to 16 was a strategic choice intended to promote a more stable learning process and achieve finer optimization of the model.\n",
        "\n",
        "Model Compilation: The model was recompiled with the Adam optimizer and an adjusted learning rate, using categorical crossentropy as the loss function, to optimize performance for our multi-class classification task.\n",
        "\n",
        "Fine-Tuning: I unfroze the last 20 layers of the EfficientNetB7 model for fine-tuning, aiming to enhance the model's ability to discern the subtle differences between airplane models and improve overall accuracy.\n",
        "\n",
        "I proceeded to train the model for an additional 50 epochs, employing callbacks such as ModelCheckpoint to save the best model and EarlyStopping to halt training if the validation loss did not improve for 10 consecutive epochs. The training process showed promising improvements. **Improved to 77.89%** by the 13th epoch. Contributed to more nuanced weight updates, allowing the model to escape potential local minima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvBCIfvTCwF9",
        "outputId": "ae5cc3a7-cb9b-4c79-92c1-4c4f642297ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3334 validated image filenames belonging to 100 classes.\n",
            "Found 3333 validated image filenames belonging to 100 classes.\n",
            "Epoch 1/50\n",
            "209/209 [==============================] - ETA: 0s - loss: 0.4400 - accuracy: 0.8659"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r209/209 [==============================] - 235s 576ms/step - loss: 0.4400 - accuracy: 0.8659 - val_loss: 1.1269 - val_accuracy: 0.7396 - lr: 1.0000e-04\n",
            "Epoch 2/50\n",
            "209/209 [==============================] - 122s 578ms/step - loss: 0.3137 - accuracy: 0.9022 - val_loss: 1.1194 - val_accuracy: 0.7525 - lr: 1.0000e-04\n",
            "Epoch 3/50\n",
            "209/209 [==============================] - 123s 586ms/step - loss: 0.2419 - accuracy: 0.9226 - val_loss: 1.0866 - val_accuracy: 0.7714 - lr: 1.0000e-04\n",
            "Epoch 4/50\n",
            "209/209 [==============================] - 113s 538ms/step - loss: 0.2108 - accuracy: 0.9331 - val_loss: 1.1366 - val_accuracy: 0.7666 - lr: 1.0000e-04\n",
            "Epoch 5/50\n",
            "209/209 [==============================] - 109s 522ms/step - loss: 0.2033 - accuracy: 0.9352 - val_loss: 1.1108 - val_accuracy: 0.7663 - lr: 1.0000e-04\n",
            "Epoch 6/50\n",
            "209/209 [==============================] - 109s 523ms/step - loss: 0.1676 - accuracy: 0.9433 - val_loss: 1.1739 - val_accuracy: 0.7699 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "209/209 [==============================] - 109s 521ms/step - loss: 0.1642 - accuracy: 0.9415 - val_loss: 1.1994 - val_accuracy: 0.7648 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "209/209 [==============================] - 110s 524ms/step - loss: 0.1498 - accuracy: 0.9514 - val_loss: 1.1737 - val_accuracy: 0.7699 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "209/209 [==============================] - 109s 522ms/step - loss: 0.1360 - accuracy: 0.9529 - val_loss: 1.1851 - val_accuracy: 0.7720 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "209/209 [==============================] - 110s 524ms/step - loss: 0.1244 - accuracy: 0.9577 - val_loss: 1.2188 - val_accuracy: 0.7681 - lr: 5.0000e-05\n",
            "Epoch 11/50\n",
            "209/209 [==============================] - 109s 523ms/step - loss: 0.1246 - accuracy: 0.9574 - val_loss: 1.2097 - val_accuracy: 0.7660 - lr: 5.0000e-05\n",
            "Epoch 12/50\n",
            "209/209 [==============================] - 109s 523ms/step - loss: 0.1084 - accuracy: 0.9640 - val_loss: 1.1791 - val_accuracy: 0.7753 - lr: 5.0000e-05\n",
            "Epoch 13/50\n",
            "209/209 [==============================] - 110s 527ms/step - loss: 0.1074 - accuracy: 0.9688 - val_loss: 1.1901 - val_accuracy: 0.7789 - lr: 5.0000e-05\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "# Load the pre-trained model\n",
        "model_path = '/content/drive/My Drive/best_model.h5'  # path to where model is stored\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    brightness_range=[0.8, 1.2]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# Using flow_from_dataframe\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_csv,\n",
        "    directory=images_dir, \n",
        "    x_col='filename',  \n",
        "    y_col='Classes', \n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_csv,\n",
        "    directory=images_dir,\n",
        "    x_col='filename',\n",
        "    y_col='Classes',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "def step_decay(epoch):\n",
        "    initial_lr = 0.0001\n",
        "    drop = 0.5\n",
        "    epochs_drop = 10.0\n",
        "    lr = initial_lr * np.power(drop, np.floor((1+epoch)/epochs_drop))\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(step_decay)\n",
        "\n",
        "# Unfreeze the last few layers for fine-tuning\n",
        "for layer in model.layers[-20:]:\n",
        "    if not isinstance(layer, keras.layers.BatchNormalization):\n",
        "        layer.trainable = True\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss=CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "checkpoint = ModelCheckpoint('/content/drive/My Drive/best_model_updated.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Training\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=50,  # epoch counts\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[checkpoint, early_stop, lr_scheduler]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Final Evaluation on Test Set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After enhancing the data augmentation strategies significantly to capture real-world variability, I ensured the model's robustness and adaptability were top-notch. By implementing a learning rate scheduler that dynamically adjusted the weights starting with an initial rate of 0.0001 and reducing it by half every 10 epochs, I aimed for fine-tuned model weights over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5OgTsHpNmuX",
        "outputId": "f27eebe0-e330-4690-f139-869ba263dd33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3333 validated image filenames belonging to 100 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_csv,\n",
        "    directory=images_dir,\n",
        "    x_col='filename',\n",
        "    y_col='Classes',  # test set labeling\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,  # batch size 16\n",
        "    class_mode='categorical',  # Using labels is categorical\n",
        "    shuffle=False  # to keep data in order\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By reducing the batch size to 16 and fine-tuning the last 20 layers of the EfficientNetB7 model, I aimed for a more precise optimization path and a deeper understanding of the dataset's intricate details. These efforts culminated in a significant improvement in the model's performance, with the final evaluation on the test set revealing a test accuracy of 77.62%. This result was a testament to the effectiveness of the adjustments made, highlighting the model's enhanced ability to classify airplane models accurately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Model Performance Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After implementing strategic improvements and optimizations, I subjected my model to a rigorous evaluation on the test set. This section delves into the detailed analysis of the model's performance, encompassing accuracy, precision, recall, and the confusion matrix, followed by a comprehensive classification report to offer insights into its capability to distinguish between the nuanced categories of airplane models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjzGo8MsNpBO",
        "outputId": "03d6c2e0-cb5f-476b-d2c2-8431a18ab78c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "209/209 [==============================] - 35s 166ms/step - loss: 1.1011 - accuracy: 0.7762\n",
            "Test Loss: 1.1010876893997192, Test Accuracy: 0.7761776447296143\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Accuracy, Precision, Recall and Confusion Matrix**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model demonstrated commendable performance on the test set, achieving an accuracy of 77.62%. This metric signifies the model's overall effectiveness in correctly identifying the airplane models from the test set. Precision, calculated as 78.89%, indicates the model's reliability in its positive predictions, while the recall of 77.62% reflects its ability to find all relevant instances within the test set. These metrics collectively suggest that the model has achieved a balanced performance in terms of both specificity and sensitivity across the different classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc_QCwfmOj9p",
        "outputId": "cabf1c93-d137-4098-e7fa-e25508cb2726"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "209/209 [==============================] - 40s 167ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(test_generator)\n",
        "predicted_classes = np.argmax(predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "mxpqqgQeOxsw"
      },
      "outputs": [],
      "source": [
        "true_classes = test_generator.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUW49X--O0v1",
        "outputId": "50965008-bf9a-4a96-c0b5-16bad582a199"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7761776177617762\n",
            "Precision: 0.7889895954133672\n",
            "Recall: 0.7761776177617762\n",
            "Confusion Matrix:\n",
            "[[27  0  0 ...  0  0  0]\n",
            " [ 0 25  0 ...  0  3  0]\n",
            " [ 1  0 28 ...  0  0  0]\n",
            " ...\n",
            " [ 0  1  0 ... 29  0  0]\n",
            " [ 0  0  0 ...  0 32  0]\n",
            " [ 0  0  0 ...  0  3 27]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(true_classes, predicted_classes)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(true_classes, predicted_classes, average='weighted')  # Using 'macro' for unweighted\n",
        "print(f'Precision: {precision}')\n",
        "\n",
        "# Recall\n",
        "recall = recall_score(true_classes, predicted_classes, average='weighted')  # Using 'macro' for unweighted\n",
        "print(f'Recall: {recall}')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "print(f'Confusion Matrix:\\n{conf_matrix}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Classification Report**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The classification report offered a detailed breakdown of the model's performance by class, including precision, recall, and f1-score for each airplane model category. This report illuminated the model's strengths in identifying specific models, such as the \"Boeing 737-800\" or \"Airbus A320\", with high precision and recall rates. It also underscored challenges in distinguishing between models with closely related features, where precision and recall were lower.\n",
        "\n",
        "For models like the \"Boeing 747-400\" and \"Airbus A340-300\", the f1-scores indicated a harmonious balance between precision and recall, suggesting effective classification by the model. However, for others like \"DC-3\" and \"MD-87\", the lower scores pointed to difficulties in classification, possibly due to the model's limitations in capturing the fine-grained distinctions necessary for accurate identification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t2fIkHsRBFJ",
        "outputId": "1935b162-0d2e-44a4-faef-1c3bb377cb03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "209/209 [==============================] - 35s 167ms/step\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "            707-320       0.66      0.82      0.73        33\n",
            "            727-200       0.78      0.76      0.77        33\n",
            "            737-200       0.97      0.82      0.89        34\n",
            "            737-300       0.62      0.45      0.53        33\n",
            "            737-400       0.74      0.76      0.75        33\n",
            "            737-500       0.68      0.68      0.68        34\n",
            "            737-600       0.64      0.82      0.72        33\n",
            "            737-700       0.63      0.73      0.68        33\n",
            "            737-800       0.70      0.62      0.66        34\n",
            "            737-900       0.83      0.76      0.79        33\n",
            "            747-100       0.57      0.24      0.34        33\n",
            "            747-200       0.61      0.65      0.63        34\n",
            "            747-300       0.55      0.33      0.42        33\n",
            "            747-400       0.54      0.79      0.64        33\n",
            "            757-200       0.65      0.76      0.70        34\n",
            "            757-300       0.78      0.88      0.83        33\n",
            "            767-200       0.69      0.73      0.71        33\n",
            "            767-300       0.49      0.71      0.58        34\n",
            "            767-400       0.80      0.73      0.76        33\n",
            "            777-200       0.48      0.45      0.47        33\n",
            "            777-300       0.79      0.88      0.83        34\n",
            "             A300B4       0.60      0.73      0.66        33\n",
            "               A310       0.62      0.70      0.66        33\n",
            "               A318       0.90      0.76      0.83        34\n",
            "               A319       0.62      0.64      0.63        33\n",
            "               A320       0.62      0.76      0.68        33\n",
            "               A321       0.69      0.85      0.76        34\n",
            "           A330-200       0.54      0.64      0.58        33\n",
            "           A330-300       0.67      0.61      0.63        33\n",
            "           A340-200       0.44      0.59      0.51        34\n",
            "           A340-300       0.60      0.45      0.52        33\n",
            "           A340-500       0.78      0.55      0.64        33\n",
            "           A340-600       0.72      0.68      0.70        34\n",
            "               A380       0.93      0.76      0.83        33\n",
            "             ATR-42       0.94      0.91      0.92        33\n",
            "             ATR-72       0.83      0.88      0.86        34\n",
            "              An-12       0.97      0.97      0.97        33\n",
            "        BAE 146-200       0.74      0.79      0.76        33\n",
            "        BAE 146-300       0.75      0.71      0.73        34\n",
            "            BAE-125       0.96      0.76      0.85        33\n",
            "    Beechcraft 1900       1.00      0.94      0.97        33\n",
            "         Boeing 717       0.62      0.74      0.68        34\n",
            "              C-130       0.87      0.82      0.84        33\n",
            "               C-47       0.43      0.48      0.46        33\n",
            "            CRJ-200       0.97      0.94      0.96        34\n",
            "            CRJ-700       0.92      0.73      0.81        33\n",
            "            CRJ-900       0.78      0.88      0.83        33\n",
            "         Cessna 172       0.72      0.97      0.82        34\n",
            "         Cessna 208       0.74      0.79      0.76        33\n",
            "         Cessna 525       0.78      0.94      0.85        33\n",
            "         Cessna 560       1.00      0.94      0.97        34\n",
            "     Challenger 600       0.84      0.94      0.89        33\n",
            "              DC-10       0.75      0.82      0.78        33\n",
            "               DC-3       0.41      0.44      0.42        34\n",
            "               DC-6       0.83      0.61      0.70        33\n",
            "               DC-8       0.71      0.52      0.60        33\n",
            "            DC-9-30       0.59      0.68      0.63        34\n",
            "              DH-82       0.74      0.97      0.84        33\n",
            "              DHC-1       0.76      0.85      0.80        33\n",
            "              DHC-6       0.96      0.71      0.81        34\n",
            "          DHC-8-100       0.85      0.85      0.85        33\n",
            "          DHC-8-300       0.93      0.85      0.89        33\n",
            "             DR-400       1.00      0.88      0.94        34\n",
            "        Dornier 328       0.97      0.94      0.95        33\n",
            "              E-170       0.96      0.76      0.85        33\n",
            "              E-190       0.87      0.79      0.83        34\n",
            "              E-195       0.81      0.88      0.84        33\n",
            "            EMB-120       0.91      0.94      0.93        33\n",
            "            ERJ 135       0.86      0.91      0.89        34\n",
            "            ERJ 145       0.74      0.79      0.76        33\n",
            " Embraer Legacy 600       0.97      0.97      0.97        33\n",
            "Eurofighter Typhoon       0.97      0.97      0.97        34\n",
            "            F-16A/B       0.94      0.88      0.91        33\n",
            "             F/A-18       0.93      0.76      0.83        33\n",
            "        Falcon 2000       0.86      0.91      0.89        34\n",
            "         Falcon 900       1.00      0.85      0.92        33\n",
            "         Fokker 100       0.67      0.79      0.72        33\n",
            "          Fokker 50       0.94      0.88      0.91        34\n",
            "          Fokker 70       0.73      0.82      0.77        33\n",
            "     Global Express       0.88      0.88      0.88        33\n",
            "      Gulfstream IV       0.86      0.88      0.87        34\n",
            "       Gulfstream V       0.92      0.73      0.81        33\n",
            "            Hawk T1       0.88      0.88      0.88        33\n",
            "              Il-76       0.94      0.88      0.91        34\n",
            "             L-1011       0.96      0.82      0.89        33\n",
            "              MD-11       0.74      0.70      0.72        33\n",
            "              MD-80       0.58      0.62      0.60        34\n",
            "              MD-87       0.43      0.61      0.51        33\n",
            "              MD-90       0.95      0.64      0.76        33\n",
            "         Metroliner       0.97      0.91      0.94        34\n",
            "         Model B200       0.91      0.91      0.91        33\n",
            "              PA-28       0.90      0.82      0.86        33\n",
            "              SR-20       0.97      0.97      0.97        34\n",
            "          Saab 2000       1.00      0.97      0.98        33\n",
            "           Saab 340       0.94      0.94      0.94        33\n",
            "           Spitfire       1.00      0.79      0.89        34\n",
            "            Tornado       0.97      0.85      0.90        33\n",
            "             Tu-134       0.85      0.88      0.87        33\n",
            "             Tu-154       0.78      0.94      0.85        34\n",
            "             Yak-42       1.00      0.82      0.90        33\n",
            "\n",
            "           accuracy                           0.78      3333\n",
            "          macro avg       0.79      0.78      0.78      3333\n",
            "       weighted avg       0.79      0.78      0.78      3333\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Make predictions\n",
        "predictions = model.predict(test_generator)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# true labels for comparison\n",
        "true_classes = test_generator.classes\n",
        "class_labels = list(test_generator.class_indices.keys())  # Getting class labels from the generator\n",
        "\n",
        "# print a confusion matrix or classification report\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(classification_report(true_classes, predicted_classes, target_names=class_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG-OLLgbR9MO"
      },
      "source": [
        "### **Demo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ns1WLvagR_dS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "import numpy as np\n",
        "\n",
        "# Load the pre-trained model\n",
        "model_path = '/content/drive/My Drive/best_model_updated.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "class_indices = train_generator.class_indices\n",
        "# Invert the dictionary to map indices to class names\n",
        "idx_to_class = {v: k for k, v in class_indices.items()}\n",
        "\n",
        "def predict_single_image(image_path, model, idx_to_class):\n",
        "    # Load and preprocess the image\n",
        "    img = image.load_img(image_path, target_size=(224, 224))  # Adjusting target_size to match model's expected input\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_preprocessed = preprocess_input(img_array)\n",
        "\n",
        "    # Predict\n",
        "    predictions = model.predict(img_preprocessed)\n",
        "    predicted_class_idx = np.argmax(predictions, axis=1)[0]\n",
        "    predicted_class = idx_to_class[predicted_class_idx]\n",
        "    confidence = np.max(predictions)\n",
        "\n",
        "    return predicted_class, confidence\n",
        "\n",
        "# Path to test image\n",
        "image_path = '/content/drive/My Drive/test/image.jpg'\n",
        "predicted_class, confidence = predict_single_image(image_path, model, idx_to_class)\n",
        "\n",
        "print(f'This image is a {predicted_class} with confidence {confidence:.2f}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
